{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn4M_kQ8TAL8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ngrok config add-authtoken 31CnZgV0BW5STRbU7ASbjoaRird_4kB842X3HP5w1ME8YY4qy\n"
      ],
      "metadata": {
        "id": "hEGlgJIGTIqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Use GPU if available\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n"
      ],
      "metadata": {
        "id": "4N4QrQipTb3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)"
      ],
      "metadata": {
        "id": "Yp43uozVTcpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = \"deepset/roberta-base-squad2\"\n",
        "qa = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_model, device=device)"
      ],
      "metadata": {
        "id": "sK_mA8DmTfHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "6jZCXiRZThWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text_by_tokens(text, tokenizer, max_tokens=1024, overlap=128):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        chunk = tokenizer.decode(tokens[i:i+max_tokens], skip_special_tokens=True)\n",
        "        chunks.append(chunk)\n",
        "        i += max_tokens - overlap\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "4YgwUJUDTjMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_long_text(text):\n",
        "    chunks = chunk_text_by_tokens(text, tokenizer)\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        out = summarizer(chunk, max_length=150, min_length=40, do_sample=False)[0]['summary_text']\n",
        "        summaries.append(out)\n",
        "    # Merge and summarize again for final concise version\n",
        "    merged = \" \".join(summaries)\n",
        "    final_summary = summarizer(merged, max_length=200, min_length=60, do_sample=False)[0]['summary_text']\n",
        "    return final_summary\n"
      ],
      "metadata": {
        "id": "e8g5bz26Tn1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_long_text(text):\n",
        "    chunks = chunk_text_by_tokens(text, tokenizer)\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        token_count = len(tokenizer.encode(chunk))\n",
        "        # Make max_length smaller than input tokens (e.g., 40% of it)\n",
        "        max_len = max(30, int(token_count * 0.4))\n",
        "        min_len = max(10, int(token_count * 0.2))\n",
        "\n",
        "        out = summarizer(\n",
        "            chunk,\n",
        "            max_length=max_len,\n",
        "            min_length=min_len,\n",
        "            do_sample=False\n",
        "        )[0]['summary_text']\n",
        "        summaries.append(out)\n",
        "\n",
        "    # Merge and do final summarization\n",
        "    merged = \" \".join(summaries)\n",
        "    token_count = len(tokenizer.encode(merged))\n",
        "    max_len = max(50, int(token_count * 0.4))\n",
        "    min_len = max(20, int(token_count * 0.2))\n",
        "\n",
        "    final_summary = summarizer(\n",
        "        merged,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        do_sample=False\n",
        "    )[0]['summary_text']\n",
        "\n",
        "    return final_summary\n"
      ],
      "metadata": {
        "id": "k81dMLXYTqMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, text):\n",
        "    chunks = chunk_text_by_tokens(text, tokenizer)\n",
        "    best_score = 0\n",
        "    best_answer = \"\"\n",
        "    for chunk in chunks:\n",
        "        result = qa(question=question, context=chunk)\n",
        "        if result['score'] > best_score:\n",
        "            best_score = result['score']\n",
        "            best_answer = result['answer']\n",
        "    return best_answer, best_score\n"
      ],
      "metadata": {
        "id": "d7iuKMalTsUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ],
      "metadata": {
        "id": "WtIriFkBTyJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text (replace with your article)\n",
        "article = \"\"\"The James Webb Space Telescope (JWST) is the largest optical telescope in space.\n",
        "It was launched on December 25, 2021, and is designed primarily to conduct infrared astronomy.\n",
        "JWST's high sensitivity allows it to view objects too old, distant, or faint for the Hubble Space Telescope.\"\"\"\n",
        "\n",
        "# Summarize\n",
        "print(\"SUMMARY:\\n\", summarize_long_text(article))\n",
        "\n",
        "# Ask question\n",
        "question = \"When was JWST launched?\"\n",
        "answer, score = answer_question(question, article)\n",
        "print(f\"\\nQ: {question}\\nA: {answer} (score: {score:.3f})\")"
      ],
      "metadata": {
        "id": "cpasLKv1T18z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "Artificial Intelligence (AI) has been rapidly evolving over the past few decades, moving from a niche research topic to one of the most significant drivers of technological change in the 21st century. Initially confined to rule-based systems and symbolic reasoning, AI has undergone a dramatic transformation, fueled by the advent of machine learning, deep learning, and access to large datasets.\n",
        "\n",
        "One of the key milestones in AI development was the creation of algorithms capable of learning from data. Unlike traditional software, where programmers explicitly define the rules, machine learning systems identify patterns and relationships in data to make predictions or decisions. This shift has allowed AI to be applied to a wide range of tasks, from image recognition and natural language processing to autonomous vehicles and medical diagnosis.\n",
        "\n",
        "Deep learning, a subfield of machine learning inspired by the structure and function of the human brain, has been especially impactful. Neural networks with many layers have shown remarkable capabilities in tasks that were once considered impossible for machines. For example, convolutional neural networks (CNNs) have revolutionized computer vision, enabling breakthroughs in facial recognition, object detection, and even art generation.\n",
        "\n",
        "The availability of vast amounts of data has played a crucial role in this transformation. The explosion of digital content, combined with advances in storage and cloud computing, has made it possible to train AI models on datasets of unprecedented scale. This, in turn, has led to more accurate and robust systems, but it has also raised concerns about privacy, security, and ethical use of data.\n",
        "\n",
        "Ethics in AI has become a major area of discussion among researchers, policymakers, and the general public. Issues such as algorithmic bias, transparency, accountability, and the potential for job displacement have sparked debates worldwide. Many experts argue that while AI has the potential to bring enormous benefits, it must be developed and deployed responsibly to ensure fairness and prevent harm.\n",
        "\n",
        "In the business world, AI is being used to optimize operations, enhance customer experiences, and create new products and services. For instance, recommendation systems, powered by AI algorithms, drive much of the engagement on platforms like Netflix, YouTube, and Amazon. In manufacturing, AI-powered predictive maintenance helps reduce downtime and improve efficiency.\n",
        "\n",
        "Healthcare has also seen transformative effects from AI. Machine learning algorithms can analyze medical images to detect diseases earlier than human doctors, assist in drug discovery by predicting molecular interactions, and even personalize treatment plans based on a patient‚Äôs genetic profile. These applications have the potential to save lives and reduce healthcare costs, but they also raise questions about the role of human judgment in medicine.\n",
        "\n",
        "Autonomous vehicles are another high-profile example of AI in action. Self-driving cars rely on a combination of sensors, cameras, and AI algorithms to navigate complex environments, recognize traffic signs, and avoid obstacles. While significant progress has been made, challenges remain in ensuring safety and dealing with unpredictable real-world scenarios.\n",
        "\n",
        "Looking ahead, AI is expected to continue advancing at a rapid pace. Emerging areas such as reinforcement learning, generative AI, and neuromorphic computing promise to push the boundaries of what AI systems can achieve. However, these advancements will also bring new challenges, including the need for more energy-efficient models and strategies to mitigate potential misuse.\n",
        "\n",
        "In conclusion, artificial intelligence has already reshaped many aspects of society, and its influence will only grow in the coming years. By addressing ethical concerns and ensuring responsible development, humanity can harness the power of AI to create a more prosperous, equitable, and sustainable future.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jhJ_eStzT5w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SUMMARY:\\n\", summarize_long_text(article))\n",
        "\n",
        "question = \"What are some ethical concerns related to AI?\"\n",
        "answer, score = answer_question(question, article)\n",
        "print(f\"\\nQ: {question}\\nA: {answer} (score: {score:.3f})\")"
      ],
      "metadata": {
        "id": "GzzRmSDFT7JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving**"
      ],
      "metadata": {
        "id": "4t_upkkuT8jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "\n",
        "summarizer.model.save_pretrained(\"/content/bart_summarizer\")\n",
        "summarizer.tokenizer.save_pretrained(\"/content/bart_summarizer\")"
      ],
      "metadata": {
        "id": "Ei8LD1JQT-yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deployment***"
      ],
      "metadata": {
        "id": "LLWOwL03UBYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# app.py\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load models once\n",
        "@st.cache_resource\n",
        "def load_pipelines():\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "    return summarizer, qa_pipeline\n",
        "\n",
        "summarizer, qa_pipeline = load_pipelines()\n",
        "\n",
        "# Page settings\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Summarizer & Q&A\",\n",
        "    page_icon=\"ü§ñ\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "# Title\n",
        "st.markdown(\"<h1 style='text-align: center; color: #4CAF50;'> AI Summarizer & Question Answering</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<p style='text-align: center; font-size: 18px;'>Paste an article, get a concise summary, and ask questions instantly!</p>\", unsafe_allow_html=True)\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Layout: Two columns\n",
        "col1, col2 = st.columns([2, 1])\n",
        "\n",
        "# Text input\n",
        "with col1:\n",
        "    st.markdown(\"###  Article Input\")\n",
        "    text_input = st.text_area(\"Enter your article text below:\", height=300, placeholder=\"Paste your text here...\")\n",
        "\n",
        "# Summarization\n",
        "with col2:\n",
        "    st.markdown(\"### Summary\")\n",
        "    if st.button(\"Summarize\", use_container_width=True, type=\"primary\"):\n",
        "        if text_input.strip():\n",
        "            summary = summarizer(text_input, max_length=150, min_length=30, do_sample=False)\n",
        "            st.success(summary[0]['summary_text'])\n",
        "        else:\n",
        "            st.warning(\"Please enter some text to summarize.\")\n",
        "\n",
        "# Question answering section\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"### ‚ùì Ask a Question\")\n",
        "question = st.text_input(\"Enter your question here:\", placeholder=\"e.g., What is the main topic?\")\n",
        "\n",
        "if st.button(\"Get Answer\", use_container_width=True):\n",
        "    if text_input.strip() and question.strip():\n",
        "        answer = qa_pipeline(question=question, context=text_input)\n",
        "        st.info(f\"**Answer:** {answer['answer']}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter both text and a question.\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"<p style='text-align: center; font-size: 14px;'>Powered by HuggingFace Transformers ;)</p>\", unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "id": "zx9BVtQNUENX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Kill any running Streamlit instances\n",
        "!pkill streamlit\n",
        "\n",
        "# Start Streamlit in background\n",
        "get_ipython().system_raw('streamlit run app.py --server.port 8501 &')\n",
        "\n",
        "# Wait for server to be ready\n",
        "time.sleep(5)\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Your app is live here: {public_url}\")\n"
      ],
      "metadata": {
        "id": "WhZ-bTVbUH88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}